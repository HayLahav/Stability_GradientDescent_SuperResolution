ax.set_ylabel('γ(m) / ||w - w\\'||')\n",
    "    ax.set_title('Stability Efficiency')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if histories:\n",
    "    # Create summary DataFrame\n",
    "    summary_data = []\n",
    "    \n",
    "    for name, history in histories.items():\n",
    "        summary = {\n",
    "            'Configuration': name,\n",
    "            'Final Train Loss': history['train_loss'][-1],\n",
    "            'Final Val Loss': history.get('val_loss', [np.nan])[-1],\n",
    "            'Min Train Loss': min(history['train_loss']),\n",
    "            'Min Val Loss': min(history.get('val_loss', [np.nan])),\n",
    "        }\n",
    "        \n",
    "        if 'parameter_distance' in history and history['parameter_distance']:\n",
    "            summary['Final Param Distance'] = history['parameter_distance'][-1]\n",
    "            summary['Max Param Distance'] = max(history['parameter_distance'])\n",
    "        \n",
    "        if 'empirical_gamma' in history and history['empirical_gamma']:\n",
    "            summary['Final Empirical γ'] = history['empirical_gamma'][-1]\n",
    "            summary['Max Empirical γ'] = max(history['empirical_gamma'])\n",
    "        \n",
    "        if 'theoretical_gamma' in history and history['theoretical_gamma']:\n",
    "            summary['Final Theoretical γ'] = history['theoretical_gamma'][-1]\n",
    "        \n",
    "        summary_data.append(summary)\n",
    "    \n",
    "    # Create and display summary table\n",
    "    df = pd.DataFrame(summary_data)\n",
    "    df = df.set_index('Configuration')\n",
    "    \n",
    "    # Display with nice formatting\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXPERIMENTAL RESULTS SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Loss metrics\n",
    "    print(\"\\nLoss Metrics:\")\n",
    "    print(df[['Final Train Loss', 'Final Val Loss', 'Min Train Loss', 'Min Val Loss']].round(4))\n",
    "    \n",
    "    # Stability metrics\n",
    "    if 'Final Param Distance' in df.columns:\n",
    "        print(\"\\nStability Metrics:\")\n",
    "        stability_cols = [col for col in df.columns if 'Param Distance' in col or 'γ' in col]\n",
    "        print(df[stability_cols].round(6))\n",
    "    \n",
    "    # Create bar plots for key metrics\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Final losses\n",
    "    ax = axes[0]\n",
    "    df[['Final Train Loss', 'Final Val Loss']].plot(kind='bar', ax=ax)\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('Final Loss Comparison')\n",
    "    ax.legend(['Training', 'Validation'])\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Parameter distances\n",
    "    if 'Final Param Distance' in df.columns:\n",
    "        ax = axes[1]\n",
    "        df['Final Param Distance'].plot(kind='bar', ax=ax, color='green')\n",
    "        ax.set_ylabel('Parameter Distance')\n",
    "        ax.set_title('Final Parameter Distance')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Empirical gamma\n",
    "    if 'Final Empirical γ' in df.columns:\n",
    "        ax = axes[2]\n",
    "        df['Final Empirical γ'].plot(kind='bar', ax=ax, color='red')\n",
    "        ax.set_ylabel('γ(m)')\n",
    "        ax.set_title('Final Empirical Stability Bound')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Learning Rate Analysis (for AdaFM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any experiment used AdaFM optimizer\n",
    "adafm_experiments = []\n",
    "for name, history in histories.items():\n",
    "    if 'learning_rate' in history and isinstance(history['learning_rate'][0], dict):\n",
    "        if 'eta_x' in history['learning_rate'][0]:\n",
    "            adafm_experiments.append(name)\n",
    "\n",
    "if adafm_experiments:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    for name in adafm_experiments:\n",
    "        history = histories[name]\n",
    "        lr_history = history['learning_rate']\n",
    "        \n",
    "        # Extract learning rates\n",
    "        eta_x = [lr['eta_x'] for lr in lr_history]\n",
    "        eta_y = [lr['eta_y'] for lr in lr_history if lr['eta_y'] is not None]\n",
    "        \n",
    "        # Plot eta_x\n",
    "        axes[0].semilogy(eta_x, linewidth=2, label=name)\n",
    "        axes[0].set_xlabel('Epoch')\n",
    "        axes[0].set_ylabel('η_x')\n",
    "        axes[0].set_title('AdaFM Learning Rate Evolution (η_x)')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot momentum parameter if available\n",
    "        if 'momentum_param' in history:\n",
    "            axes[1].plot(history['momentum_param'], linewidth=2, label=name)\n",
    "            axes[1].set_xlabel('Epoch')\n",
    "            axes[1].set_ylabel('β(t)')\n",
    "            axes[1].set_title('Momentum Parameter Evolution')\n",
    "            axes[1].legend()\n",
    "            axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nAdaFM Optimizer Statistics:\")\n",
    "    for name in adafm_experiments:\n",
    "        lr_history = histories[name]['learning_rate']\n",
    "        final_lr = lr_history[-1]['eta_x']\n",
    "        initial_lr = lr_history[0]['eta_x'] if lr_history[0]['eta_x'] > 0 else lr_history[1]['eta_x']\n",
    "        print(f\"  {name}: Initial η={initial_lr:.6f}, Final η={final_lr:.6f}, Reduction={initial_lr/final_lr:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation results if available\n",
    "eval_results = {}\n",
    "for name, path in experiments.items():\n",
    "    eval_path = Path(path).parent / 'eval_results.pt'\n",
    "    if eval_path.exists():\n",
    "        eval_results[name] = torch.load(eval_path)\n",
    "\n",
    "if eval_results:\n",
    "    # Create performance comparison\n",
    "    metrics = ['psnr_mean', 'ssim_mean', 'mse_mean']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        values = []\n",
    "        names = []\n",
    "        errors = []\n",
    "        \n",
    "        for name, results in eval_results.items():\n",
    "            if metric in results:\n",
    "                values.append(results[metric])\n",
    "                names.append(name)\n",
    "                # Get std if available\n",
    "                std_key = metric.replace('_mean', '_std')\n",
    "                if std_key in results:\n",
    "                    errors.append(results[std_key])\n",
    "                else:\n",
    "                    errors.append(0)\n",
    "        \n",
    "        ax = axes[i]\n",
    "        bars = ax.bar(names, values, yerr=errors if errors else None, capsize=5)\n",
    "        ax.set_ylabel(metric.upper().replace('_MEAN', ''))\n",
    "        ax.set_title(f'{metric.upper().replace(\"_MEAN\", \"\")} Comparison')\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, val in zip(bars, values):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{val:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(\"\\nDetailed Evaluation Results:\")\n",
    "    for name, results in eval_results.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        for metric, value in results.items():\n",
    "            print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Results for Paper/Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate publication-ready plots\n",
    "if histories:\n",
    "    # Set publication style\n",
    "    plt.style.use('seaborn-v0_8-paper')\n",
    "    \n",
    "    # Main comparison plot\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "    \n",
    "    # Reorder for better visualization\n",
    "    ordered_names = ['Baseline', 'With Correction', 'With AdaFM Opt', 'Full System']\n",
    "    ordered_histories = {name: histories[name] for name in ordered_names if name in histories}\n",
    "    \n",
    "    # Define colors\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "    \n",
    "    # Training loss\n",
    "    ax = axes[0, 0]\n",
    "    for (name, history), color in zip(ordered_histories.items(), colors):\n",
    "        ax.plot(history['train_loss'], linewidth=2.5, label=name, color=color)\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('Training Loss', fontsize=12)\n",
    "    ax.set_title('(a) Training Convergence', fontsize=14)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Parameter distance\n",
    "    ax = axes[0, 1]\n",
    "    for (name, history), color in zip(ordered_histories.items(), colors):\n",
    "        if 'parameter_distance' in history:\n",
    "            ax.plot(history['parameter_distance'], linewidth=2.5, label=name, color=color)\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('||w - w\\'||', fontsize=12)\n",
    "    ax.set_title('(b) Parameter Stability', fontsize=14)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Empirical gamma\n",
    "    ax = axes[1, 0]\n",
    "    for (name, history), color in zip(ordered_histories.items(), colors):\n",
    "        if 'empirical_gamma' in history:\n",
    "            ax.semilogy(history['empirical_gamma'], linewidth=2.5, label=name, color=color)\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('γ(m)', fontsize=12)\n",
    "    ax.set_title('(c) Empirical Stability Bound', fontsize=14)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Generalization gap\n",
    "    ax = axes[1, 1]\n",
    "    for (name, history), color in zip(ordered_histories.items(), colors):\n",
    "        if 'val_loss' in history:\n",
    "            gen_gap = np.array(history['val_loss']) - np.array(history['train_loss'])\n",
    "            ax.plot(gen_gap, linewidth=2.5, label=name, color=color)\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('Generalization Gap', fontsize=12)\n",
    "    ax.set_title('(d) Generalization Performance', fontsize=14)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    save_path = Path('results/figures/main_comparison.pdf')\n",
    "    save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(save_path.with_suffix('.png'), dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved figure to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Generate LaTeX table\n",
    "    if eval_results:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"LaTeX Table for Paper:\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"\\\\begin{table}[h]\")\n",
    "        print(\"\\\\centering\")\n",
    "        print(\"\\\\caption{Experimental Results Summary}\")\n",
    "        print(\"\\\\begin{tabular}{lcccc}\")\n",
    "        print(\"\\\\hline\")\n",
    "        print(\"Configuration & PSNR (dB) & SSIM & MSE & Final $\\\\gamma(m)$ \\\\\\\\\")\n",
    "        print(\"\\\\hline\")\n",
    "        \n",
    "        for name in ordered_names:\n",
    "            if name in eval_results and name in histories:\n",
    "                psnr = eval_results[name].get('psnr_mean', 0)\n",
    "                ssim = eval_results[name].get('ssim_mean', 0)\n",
    "                mse = eval_results[name].get('mse_mean', 0)\n",
    "                gamma = histories[name].get('empirical_gamma', [0])[-1]\n",
    "                \n",
    "                print(f\"{name} & {psnr:.2f} & {ssim:.3f} & {mse:.4f} & {gamma:.4f} \\\\\\\\\")\n",
    "        \n",
    "        print(\"\\\\hline\")\n",
    "        print(\"\\\\end{tabular}\")\n",
    "        print(\"\\\\end{table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides comprehensive visualization of the experimental results, including:\n",
    "- Training and validation curves\n",
    "- Stability metrics comparison\n",
    "- Statistical summaries\n",
    "- Performance evaluation\n",
    "- Publication-ready figures and tables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Visualization\n",
    "\n",
    "Load and visualize results from the main stability analysis experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from src.utils import plot_stability_analysis, plot_theoretical_bounds\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Experimental Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define experiment names and paths\n",
    "experiments = {\n",
    "    'Baseline': 'results/Baseline/history.pt',\n",
    "    'With Correction': 'results/WithCorrection/history.pt',\n",
    "    'With AdaFM Opt': 'results/WithAdaFMOpt/history.pt',\n",
    "    'Full System': 'results/FullSystem/history.pt'\n",
    "}\n",
    "\n",
    "# Load histories\n",
    "histories = {}\n",
    "for name, path in experiments.items():\n",
    "    if Path(path).exists():\n",
    "        histories[name] = torch.load(path)\n",
    "        print(f\"✓ Loaded {name}\")\n",
    "    else:\n",
    "        print(f\"✗ {name} not found at {path}\")\n",
    "\n",
    "if not histories:\n",
    "    print(\"\\nNo experimental results found. Please run experiments first:\")\n",
    "    print(\"  bash scripts/run_all_experiments.sh\")\n",
    "else:\n",
    "    print(f\"\\nLoaded {len(histories)} experiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training and Validation Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if histories:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Training loss\n",
    "    for name, history in histories.items():\n",
    "        ax1.plot(history['train_loss'], linewidth=2, label=name)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Training Loss')\n",
    "    ax1.set_title('Training Loss Comparison')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Validation loss\n",
    "    for name, history in histories.items():\n",
    "        if 'val_loss' in history:\n",
    "            ax2.plot(history['val_loss'], linewidth=2, label=name)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Validation Loss')\n",
    "    ax2.set_title('Validation Loss Comparison')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print final losses\n",
    "    print(\"\\nFinal Training Losses:\")\n",
    "    for name, history in histories.items():\n",
    "        final_train = history['train_loss'][-1]\n",
    "        final_val = history.get('val_loss', [0])[-1]\n",
    "        print(f\"  {name}: Train={final_train:.4f}, Val={final_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stability Analysis Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if histories:\n",
    "    # Use the built-in visualization function\n",
    "    plot_stability_analysis(histories, figsize=(18, 12))\n",
    "    \n",
    "    # Additional detailed stability metrics\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Parameter distance growth rate\n",
    "    ax = axes[0, 0]\n",
    "    for name, history in histories.items():\n",
    "        if 'parameter_distance' in history and len(history['parameter_distance']) > 1:\n",
    "            growth_rate = np.diff(history['parameter_distance'])\n",
    "            ax.plot(growth_rate, linewidth=2, label=name)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Growth Rate')\n",
    "    ax.set_title('Parameter Distance Growth Rate')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Empirical gamma normalized\n",
    "    ax = axes[0, 1]\n",
    "    for name, history in histories.items():\n",
    "        if 'empirical_gamma' in history and history['empirical_gamma']:\n",
    "            normalized = np.array(history['empirical_gamma']) / history['empirical_gamma'][0]\n",
    "            ax.plot(normalized, linewidth=2, label=name)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Normalized γ(m)')\n",
    "    ax.set_title('Normalized Empirical Stability (γ(m) / γ₀)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Generalization gap\n",
    "    ax = axes[1, 0]\n",
    "    for name, history in histories.items():\n",
    "        if 'val_loss' in history and 'train_loss' in history:\n",
    "            gen_gap = np.array(history['val_loss']) - np.array(history['train_loss'])\n",
    "            ax.plot(gen_gap, linewidth=2, label=name)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Val Loss - Train Loss')\n",
    "    ax.set_title('Generalization Gap Evolution')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Stability efficiency (gamma / param_distance)\n",
    "    ax = axes[1, 1]\n",
    "    for name, history in histories.items():\n",
    "        if 'empirical_gamma' in history and 'parameter_distance' in history:\n",
    "            gamma = np.array(history['empirical_gamma'])\n",
    "            dist = np.array(history['parameter_distance'])\n",
    "            efficiency = gamma / (dist + 1e-8)\n",
    "            ax.semilogy(efficiency, linewidth=2, label=name)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_